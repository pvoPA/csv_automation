"""
Exports vulnerability data to CSV on
    tanzu application service resources in Prisma Cloud.

This script is used to retrieve vulnerability data
    for tanzu application service resources and
    exports it to a CSV file with the following actions,
        - Generate Prisma Token
        - Delete the CSV file if it exists from a previous run
        - Grab tanzu application service scan results
        - For each API call,
            - Flatten vulnerability list for each tanzu application service
            - Write to CSV (Create a CSV directory and file.)

Usage:
    python export_tas_vulnerability_csv.py

Options:

Requirements:
    - Python 3.10 or higher
    - .env configured with the following variables,
        - PRISMA_ACCESS_KEY
        - PRISMA_SECRET_KEY

Example:
    python export_tas_vulnerability_csv.py

Note:
    This script is meant to be deployed in the following platforms,
        - docker container
            - the app directory
        - azure function
            - the azure-function directory
        - aws lambda function
            - the aws-lambda directory
"""
import os
import json
import datetime as dt
from helpers import logger
from helpers import prisma_get_images_scan_results
from helpers import generate_prisma_token
from helpers import write_data_to_csv
from helpers import prisma_get_containers_scan_results


def etl_tas_vulnerability_csv():
    """
    Gets tanzu application service data from Prisma and export to CSV.

    Parameters:
        None

    Returns:
        None

    """
    todays_date = str(dt.datetime.today()).split()[0]
    COLLECTIONS_FILTER = ", ".join(json.loads(os.getenv("TAS_COLLECTIONS_FILTER")))
    tas_blobstore_vulnerability_csv_name = os.getenv("TAS_VULNERABILITY_CSV_NAME")
    tas_blobstore_vulnerability_fields_of_interest = json.loads(
        os.getenv("TAS_VULNERABILITY_FIELDS_OF_INTEREST")
    )

    file_path = f"CSVs/{tas_blobstore_vulnerability_csv_name}_{todays_date}.csv"
    prisma_access_key = os.getenv("PRISMA_ACCESS_KEY")
    prisma_secret_key = os.getenv("PRISMA_SECRET_KEY")
    external_labels_to_include = json.loads(os.getenv("TAS_EXTERNAL_LABELS_TO_INCLUDE"))

    tas_csv_fields = [
        "labels",
        "type",
        "appEmbedded",
        "description",
        "firewallProtection",
        "clusters",
        "hostname",
        "scanVersion",
        "tags",
        "scanBuildDate",
        "Secrets",
        "binaries",
        "packageCorrelationDone",
        "layerTime",
        "scanTime",
        "wildFireUsage",
        "twistlock",
        "packages",
        "published",
        "_id",
        "complianceIssues",
        "distro",
        "text",
        "repoDigests",
        "hosts",
        "scanID",
        "vulnerabilitiesCount",
        "packageName",
        "isARM64",
        "id",
        "allCompliance",
        "status",
        "err",
        "severity",
        "cri",
        "functionLayer",
        "osDistro",
        "osDistroRelease",
        "creationTime",
        "cloudMetadata",
        "layers",
        "collections",
        "cause",
        "topLayer",
        "packageVersion",
        "exploit",
        "applicableRules",
        "trustStatus",
        "vulnerabilityRiskScore",
        "repoTag",
        "vulnerabilityDistribution",
        "vecStr",
        "instances",
        "title",
        "complianceDistribution",
        "firstScanTime",
        "cvss",
        "startupBinaries",
        "image",
        "link",
        "riskFactors",
        "pushTime",
        "complianceRiskScore",
        "files",
        "history",
        "agentless",
        "installedProducts",
        "complianceIssuesCount",
        "cve",
        "templates",
        "fixDate",
        "discovered",
        "osDistroVersion",
        "packageManager",
        "binaryPkgs",
        "exploits",
        "applications",
        "vulnTagInfos",
        "missingDistroVulnCoverage",
        "namespaces",
        "externalLabels",
        "rhelRepos",
        "gracePeriodDays",
        "block",
        "twistlockImage",
        "Package_Path",
        "Incremental_ID",
    ]

    for external_label in external_labels_to_include:
        tas_csv_fields.append(external_label)

    ###########################################################################
    # Generate Prisma Token

    prisma_token = generate_prisma_token(prisma_access_key, prisma_secret_key)

    ###########################################################################
    # Delete the CSV file if it exists from a previous run

    try:
        os.remove(file_path)
    except FileNotFoundError:
        pass

    ###########################################################################
    # Get images from Prisma and write to CSV

    end_of_page = False
    new_file = True
    offset = 0
    page_limit = 50
    tas_vulnerability_dict = dict()

    while not end_of_page:
        (
            tas_response,
            status_code,
        ) = prisma_get_images_scan_results(
            prisma_token, offset=offset, limit=page_limit, collection=COLLECTIONS_FILTER
        )

        if status_code == 200:
            if tas_response:
                ###############################################################
                # Flatten vulnerability list for each blob
                for tas in tas_response:
                    external_labels = dict()
                    if "externalLabels" in tas:
                        for external_label in tas["externalLabels"]:
                            if external_label["key"] in external_labels_to_include:
                                external_labels.update(
                                    {external_label["key"]: external_label["value"]}
                                )
                    if "vulnerabilities" in tas:
                        if tas["vulnerabilities"]:
                            for vuln in tas["vulnerabilities"]:
                                # Grab base host information
                                vulnerability_dict = {
                                    key: value
                                    for key, value in tas.items()
                                    if (
                                        key
                                        in tas_blobstore_vulnerability_fields_of_interest
                                    )
                                }

                                # Add the individual vulnerability information
                                vulnerability_dict.update(
                                    {
                                        key: value
                                        for key, value in vuln.items()
                                        if (
                                            key
                                            in tas_blobstore_vulnerability_fields_of_interest
                                        )
                                    }
                                )

                                # Get the package info and install path
                                PACKAGE_NAME = vuln["packageName"]
                                PACKAGE_VERSION = vuln["packageVersion"]
                                PACKAGE_PATH = "NOT_AVAILABLE"

                                package_found = False

                                if PACKAGE_NAME:
                                    for package_type in tas["packages"]:
                                        for package in package_type["pkgs"]:
                                            if (
                                                package["name"] == PACKAGE_NAME
                                                and package["version"]
                                                == PACKAGE_VERSION
                                            ):
                                                if "path" in package:
                                                    PACKAGE_PATH = package["path"]
                                                package_found = True
                                                break

                                    # Check "applications" field for package path
                                    if not package_found:
                                        if "applications" in tas:
                                            for app in tas["applications"]:
                                                if (
                                                    app["name"] == PACKAGE_NAME
                                                    and app["version"]
                                                    == PACKAGE_VERSION
                                                ):
                                                    PACKAGE_PATH = app["path"]
                                                    package_found = True
                                                    break

                                    # Check "binaries" field for package path
                                    if not package_found:
                                        if "binaries" in tas:
                                            for binary in tas["binaries"]:
                                                if binary["name"] == PACKAGE_NAME:
                                                    PACKAGE_PATH = binary["path"]
                                                    package_found = True
                                                    break

                                    # Check "startupBinaries" field for package path
                                    if not package_found:
                                        if "binaries" in tas:
                                            for binary in tas["binaries"]:
                                                if binary["name"] == PACKAGE_NAME:
                                                    PACKAGE_PATH = binary["path"]
                                                    package_found = True
                                                    break

                                if package_found:
                                    vulnerability_dict["Package_Path"] = PACKAGE_PATH

                                if tas["_id"] in tas_vulnerability_dict:
                                    tas_vulnerability_dict[tas["_id"]].append(
                                        vulnerability_dict
                                    )
                                else:
                                    tas_vulnerability_dict.update(
                                        {tas["_id"]: [vulnerability_dict]}
                                    )

                ###############################################################
                # Write to CSV
                # write_data_to_csv(
                #     file_path, vulnerability_list, tas_csv_fields, new_file
                # )
                # new_file = False

                offset += page_limit
            else:
                end_of_page = True
                break
        elif status_code == 401:
            logger.error("Prisma token timed out, generating a new one and continuing.")

            prisma_token = generate_prisma_token(prisma_access_key, prisma_secret_key)
        else:
            logger.error("API returned %s.", status_code)

    ###########################################################################
    # Get collection IDs for TAS vulnerability correlation and write to CSV

    end_of_page = False
    offset = 0
    LIMIT = 50
    incremental_id = 0
    new_file = True

    while not end_of_page:
        containers_response, status_code = prisma_get_containers_scan_results(
            prisma_token, offset=offset, limit=LIMIT, collection=COLLECTIONS_FILTER
        )
        if status_code == 200:
            if containers_response:
                csv_rows = list()

                for container in containers_response:
                    IMAGE_ID = container["info"]["imageID"]
                    if IMAGE_ID in tas_vulnerability_dict:
                        for vuln in tas_vulnerability_dict[IMAGE_ID]:
                            vuln.update({"Incremental_ID": incremental_id})

                            csv_rows.append(vuln)

                            incremental_id += 1

                        # remove the image ID as it's already been added to the CSV
                        tas_vulnerability_dict.pop(IMAGE_ID)

                write_data_to_csv(file_path, csv_rows, tas_csv_fields, new_file)
                new_file = False
            else:
                end_of_page = True

            offset += LIMIT
        elif status_code == 401:
            logger.error("Prisma token timed out, generating a new one and continuing.")

            prisma_token = generate_prisma_token(prisma_access_key, prisma_secret_key)
        else:
            logger.error("API returned %s.", status_code)


if __name__ == "__main__":
    logger.info("Creating tanzu application service vulnerabilities CSV...")

    etl_tas_vulnerability_csv()
