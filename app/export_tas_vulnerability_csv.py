"""
Exports vulnerability data to CSV on
    tanzu application service resources in Prisma Cloud.

This script is used to retrieve vulnerability data
    for tanzu application service resources and
    exports it to a CSV file with the following actions,
        - Generate Prisma Token
        - Delete the CSV file if it exists from a previous run
        - Grab tanzu application service scan results
        - For each API call,
            - Flatten vulnerability list for each tanzu application service
            - Write to CSV (Create a CSV directory and file.)

Usage:
    python export_tas_vulnerability_csv.py

Options:

Requirements:
    - Python 3.10 or higher
    - .env configured with the following variables,
        - PRISMA_ACCESS_KEY
        - PRISMA_SECRET_KEY

Example:
    python export_tas_vulnerability_csv.py

Note:
    This script is meant to be deployed in the following platforms,
        - docker container
            - the app directory
        - azure function
            - the azure-function directory
        - aws lambda function
            - the aws-lambda directory
"""
import os
import json
import datetime as dt
from azure.core import exceptions
from azure.storage.blob import BlobServiceClient
from helpers import logger
from helpers import prisma_get_images_scan_results
from helpers import generate_prisma_token
from helpers import write_data_to_csv
from helpers import write_csv_to_blob
from helpers import prisma_get_containers_scan_results


def etl_tas_vulnerability_csv():
    """
    Gets tanzu application service data from Prisma and export to CSV.

    Parameters:
        None

    Returns:
        None

    """
    todays_date = str(dt.datetime.today()).split()[0]
    COLLECTIONS_FILTER = ", ".join(json.loads(os.getenv("TAS_COLLECTIONS_FILTER")))
    tas_blobstore_vulnerability_csv_name = os.getenv("TAS_VULNERABILITY_CSV_NAME")
    tas_blobstore_vulnerability_fields_of_interest = json.loads(
        os.getenv("TAS_VULNERABILITY_FIELDS_OF_INTEREST")
    )

    blob_name = f"CSVs/{tas_blobstore_vulnerability_csv_name}_{todays_date}.csv"
    blob_store_connection_string = os.getenv("AzureWebJobsStorage")
    prisma_access_key = os.getenv("PRISMA_ACCESS_KEY")
    prisma_secret_key = os.getenv("PRISMA_SECRET_KEY")
    external_labels_to_include = json.loads(os.getenv("TAS_EXTERNAL_LABELS_TO_INCLUDE"))

    tas_csv_fields = json.loads(os.getenv("TAS_VULNERABILITY_CSV_COLUMNS"))

    for external_label in external_labels_to_include:
        tas_csv_fields.append(external_label)

    ###########################################################################
    # Initialize blob store client

    blob_service_client = BlobServiceClient.from_connection_string(
        blob_store_connection_string
    )

    container_name = os.getenv("STORAGE_ACCOUNT_CONTAINER_NAME")
    try:
        container_client = blob_service_client.get_container_client(container_name)
    except exceptions.ResourceNotFoundError:
        container_client = blob_service_client.create_container(container_name)
    blob_client = container_client.get_blob_client(blob_name)

    ###########################################################################
    # Delete the CSV file if it exists from a previous run
    try:
        container_client.delete_blob(blob_name)
    except exceptions.ResourceNotFoundError:
        pass

    ###########################################################################
    # Generate Prisma Token

    prisma_token = generate_prisma_token(prisma_access_key, prisma_secret_key)

    ###########################################################################
    # Get images from Prisma and write to CSV

    end_of_page = False
    offset = 0
    page_limit = 50
    tas_vulnerability_dict = dict()

    while not end_of_page:
        (
            tas_response,
            status_code,
        ) = prisma_get_images_scan_results(
            prisma_token,
            offset=offset,
            limit=page_limit,
            collection=COLLECTIONS_FILTER,
        )

        if status_code == 200:
            if tas_response:
                ###############################################################
                # Flatten vulnerability list for each blob
                for tas in tas_response:
                    external_labels = dict()
                    if "externalLabels" in tas:
                        for external_label in tas["externalLabels"]:
                            if external_label["key"] in external_labels_to_include:
                                external_labels.update(
                                    {external_label["key"]: external_label["value"]}
                                )
                    if "vulnerabilities" in tas:
                        if tas["vulnerabilities"]:
                            for vuln in tas["vulnerabilities"]:
                                vulnerability_dict = {"resourceID": tas["_id"]}

                                # Add the individual vulnerability information
                                vulnerability_dict.update(
                                    {
                                        key: value
                                        for key, value in vuln.items()
                                        if (
                                            key
                                            in tas_blobstore_vulnerability_fields_of_interest
                                        )
                                    }
                                )

                                # Get the package info and install path
                                PACKAGE_NAME = vuln["packageName"]
                                PACKAGE_VERSION = vuln["packageVersion"]
                                PACKAGE_PATH = "NOT_AVAILABLE"

                                package_found = False

                                if PACKAGE_NAME:
                                    for package_type in tas["packages"]:
                                        for package in package_type["pkgs"]:
                                            if (
                                                package["name"] == PACKAGE_NAME
                                                and package["version"]
                                                == PACKAGE_VERSION
                                            ):
                                                if "path" in package:
                                                    PACKAGE_PATH = package["path"]
                                                package_found = True
                                                break

                                    # Check "applications" field for package path
                                    if not package_found:
                                        if "applications" in tas:
                                            for app in tas["applications"]:
                                                if (
                                                    app["name"] == PACKAGE_NAME
                                                    and app["version"]
                                                    == PACKAGE_VERSION
                                                ):
                                                    PACKAGE_PATH = app["path"]
                                                    package_found = True
                                                    break

                                    # Check "binaries" field for package path
                                    if not package_found:
                                        if "binaries" in tas:
                                            for binary in tas["binaries"]:
                                                if binary["name"] == PACKAGE_NAME:
                                                    PACKAGE_PATH = binary["path"]
                                                    package_found = True
                                                    break

                                    # Check "startupBinaries" field for package path
                                    if not package_found:
                                        if "binaries" in tas:
                                            for binary in tas["binaries"]:
                                                if binary["name"] == PACKAGE_NAME:
                                                    PACKAGE_PATH = binary["path"]
                                                    package_found = True
                                                    break

                                if package_found:
                                    vulnerability_dict["Package_Path"] = PACKAGE_PATH

                                if tas["_id"] in tas_vulnerability_dict:
                                    tas_vulnerability_dict[tas["_id"]].append(
                                        vulnerability_dict
                                    )
                                else:
                                    tas_vulnerability_dict.update(
                                        {tas["_id"]: [vulnerability_dict]}
                                    )

                offset += page_limit
            else:
                end_of_page = True
                break
        elif status_code == 401:
            logger.error("Prisma token timed out, generating a new one and continuing.")

            prisma_token = generate_prisma_token(prisma_access_key, prisma_secret_key)
        else:
            logger.error("API returned %s.", status_code)

    ###########################################################################
    # Get collection IDs for TAS vulnerability correlation and write to CSV

    end_of_page = False
    offset = 0
    LIMIT = 50
    incremental_id = 0
    csv_rows = list()

    while not end_of_page:
        containers_response, status_code = prisma_get_containers_scan_results(
            prisma_token, offset=offset, limit=LIMIT, collection=COLLECTIONS_FILTER
        )
        if status_code == 200:
            if containers_response:
                for container in containers_response:
                    IMAGE_ID = container["info"]["imageID"]
                    if IMAGE_ID in tas_vulnerability_dict:
                        for vuln in tas_vulnerability_dict[IMAGE_ID]:
                            vuln.update(
                                {
                                    "Incremental_ID": incremental_id,
                                    "Container_ID": container["_id"],
                                    "Resource_ID": IMAGE_ID,
                                }
                            )

                            csv_rows.append(vuln)

                            incremental_id += 1

                        # remove the image ID as it's already been added to the CSV
                        tas_vulnerability_dict.pop(IMAGE_ID)

            else:
                end_of_page = True

            offset += LIMIT
        elif status_code == 401:
            logger.error("Prisma token timed out, generating a new one and continuing.")

            prisma_token = generate_prisma_token(prisma_access_key, prisma_secret_key)
        else:
            logger.error("API returned %s.", status_code)

    if csv_rows:
        write_csv_to_blob(
            blob_name, csv_rows, tas_csv_fields, blob_client, new_file=True
        )
    else:
        logger.info("No data to write to CSV, it will not be created.")


if __name__ == "__main__":
    logger.info("Creating tanzu application service vulnerabilities CSV...")

    etl_tas_vulnerability_csv()
